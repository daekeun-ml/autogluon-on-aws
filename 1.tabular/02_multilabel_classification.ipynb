{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tired-hardwood",
   "metadata": {},
   "source": [
    "# Multi-Label Prediction\n",
    "\n",
    "사용자 정의 클래스를 추가하여, 다중 레이블에 대해서도 쉽게 훈련을 수행할 수 있습니다. 본 핸즈온을 통해 다중 레이블 훈련의 예시를 살펴 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-preliminary",
   "metadata": {},
   "source": [
    "## 1. MultilabelPredictor Class\n",
    "\n",
    "사용자 지정 MultilabelPredictor 클래스를 정의하여 각 레이블에 대해 하나씩 TabularPredictor 개체 컬렉션을 관리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handmade-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.core.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str]\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str]\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = self.eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l!=label]\n",
    "            else:\n",
    "                labels_to_drop = [labels[j] for j in range(i+1,len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-conference",
   "metadata": {},
   "source": [
    "## 2. Data preparation and Training\n",
    "\n",
    "`01_binary_classification.ipynb`와 동일한 데이터셋을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "center-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-metropolitan",
   "metadata": {},
   "source": [
    "이번에는 교육 기간, 학력, 개인 소득을 동시에 예측해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accepted-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['education-num','education','class']  # which columns to predict based on the others\n",
    "problem_types = ['regression','multiclass','binary']  # type of each prediction problem\n",
    "save_path = 'ag-02-multilabel'\n",
    "time_limit = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offensive-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-characterization",
   "metadata": {},
   "source": [
    "사용자 정의 클래스로 훈련을 수행합니다. 만약 다중 레이블의 상관 관계를 고려해야 한다면, `consider_labels_correlation=True`로 설정하고 개별적으로 예측하려면 `consider_labels_correlation=False`로 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "turned-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"ag-02-multilabel/Predictor_education-num/\"\n",
      "AutoGluon Version:  0.1.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 12\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "NumExpr defaulting to 8 threads.\n",
      "\tAvailable Memory:                    59691.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: education-num ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 7 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 7 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\t\t('int', [])      : 5 | ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t0.1s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting model: RandomForestMSE ... Training model for up to 59.85s of the 59.84s of remaining time.\n",
      "\t-2.2493\t = Validation root_mean_squared_error score\n",
      "\t0.83s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 58.87s of the 58.87s of remaining time.\n",
      "\t-2.4398\t = Validation root_mean_squared_error score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 57.86s of the 57.85s of remaining time.\n",
      "\t-2.703\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 57.74s of the 57.74s of remaining time.\n",
      "\t-2.7447\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 57.63s of the 57.63s of remaining time.\n",
      "\t-2.3176\t = Validation root_mean_squared_error score\n",
      "\t0.75s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 56.84s of the 56.83s of remaining time.\n",
      "\t-2.2917\t = Validation root_mean_squared_error score\n",
      "\t3.43s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 53.37s of the 53.37s of remaining time.\n",
      "\t-2.1916\t = Validation root_mean_squared_error score\n",
      "\t1.6s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 51.75s of the 51.74s of remaining time.\n",
      "\t-2.1739\t = Validation root_mean_squared_error score\n",
      "\t0.62s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 51.08s of the 51.07s of remaining time.\n",
      "\t-2.6378\t = Validation root_mean_squared_error score\n",
      "\t7.38s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 43.64s of the 43.63s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-7.6062\t = Validation root_mean_squared_error score\n",
      "\t37.71s\t = Training runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 5.6s of the 5.6s of remaining time.\n",
      "\t-2.3296\t = Validation root_mean_squared_error score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.85s of the 3.8s of remaining time.\n",
      "\t-2.1322\t = Validation root_mean_squared_error score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 56.95s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag-02-multilabel/Predictor_education-num/\")\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"ag-02-multilabel/Predictor_education/\"\n",
      "AutoGluon Version:  0.1.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 13\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 11 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.976\n",
      "Train Data Class Count: 11\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    56929.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 7 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 7 | ['workclass', 'marital-status', 'occupation', 'relationship', 'race', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 390, Val Rows: 98\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 59.87s of the 59.87s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: education ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7755\t = Validation accuracy score\n",
      "\t12.72s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 47.1s of the 47.1s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7245\t = Validation accuracy score\n",
      "\t21.25s\t = Training runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 25.57s of the 25.56s of remaining time.\n",
      "\t0.2653\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 25.45s of the 25.45s of remaining time.\n",
      "\t0.2347\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 25.34s of the 25.34s of remaining time.\n",
      "\t0.9082\t = Validation accuracy score\n",
      "\t1.01s\t = Training runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 24.08s of the 24.08s of remaining time.\n",
      "\t0.8776\t = Validation accuracy score\n",
      "\t0.99s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 22.95s of the 22.95s of remaining time.\n",
      "\t0.9694\t = Validation accuracy score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 21.93s of the 21.93s of remaining time.\n",
      "\t0.9592\t = Validation accuracy score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 20.92s of the 20.91s of remaining time.\n",
      "\t1.0\t = Validation accuracy score\n",
      "\t0.69s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 20.19s of the 20.19s of remaining time.\n",
      "\t0.9796\t = Validation accuracy score\n",
      "\t0.95s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 19.16s of the 19.16s of remaining time.\n",
      "\t1.0\t = Validation accuracy score\n",
      "\t7.39s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 11.75s of the 11.75s of remaining time.\n",
      "\t1.0\t = Validation accuracy score\n",
      "\t12.24s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.87s of the -1.92s of remaining time.\n",
      "\t1.0\t = Validation accuracy score\n",
      "\t0.46s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 62.4s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag-02-multilabel/Predictor_education/\")\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"ag-02-multilabel/Predictor_class/\"\n",
      "AutoGluon Version:  0.1.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    56883.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting model: RandomForestGini ... Training model for up to 59.87s of the 59.87s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: class ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.84\t = Validation accuracy score\n",
      "\t0.87s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 58.88s of the 58.88s of remaining time.\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 57.89s of the 57.89s of remaining time.\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 57.0s of the 56.99s of remaining time.\n",
      "\t0.84\t = Validation accuracy score\n",
      "\t0.76s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 56.1s of the 56.1s of remaining time.\n",
      "\t0.73\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 55.99s of the 55.99s of remaining time.\n",
      "\t0.65\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 55.88s of the 55.88s of remaining time.\n",
      "\t0.85\t = Validation accuracy score\n",
      "\t0.31s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 55.54s of the 55.53s of remaining time.\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t0.25s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 55.26s of the 55.26s of remaining time.\n",
      "\t0.86\t = Validation accuracy score\n",
      "\t1.45s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 53.79s of the 53.79s of remaining time.\n",
      "\t0.85\t = Validation accuracy score\n",
      "\t0.52s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 53.23s of the 53.23s of remaining time.\n",
      "\t0.76\t = Validation accuracy score\n",
      "\t3.75s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 49.41s of the 49.41s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.83\t = Validation accuracy score\n",
      "\t18.05s\t = Training runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 31.09s of the 31.09s of remaining time.\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t0.5s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.87s of the 29.25s of remaining time.\n",
      "\t0.86\t = Validation accuracy score\n",
      "\t0.54s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 31.32s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag-02-multilabel/Predictor_class/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('ag-02-multilabel/')\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels, problem_types=problem_types, path=save_path)\n",
    "multi_predictor.fit(train_data, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-designation",
   "metadata": {},
   "source": [
    "## 3. Inference and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "included-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>41</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>408498</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>746786</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>50</td>\n",
       "      <td>Private</td>\n",
       "      <td>62593</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>248178</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>43</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>52849</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass  fnlwgt       marital-status        occupation  \\\n",
       "5454   41   Self-emp-not-inc  408498   Married-civ-spouse   Exec-managerial   \n",
       "6111   39            Private  746786   Married-civ-spouse    Prof-specialty   \n",
       "5282   50            Private   62593   Married-civ-spouse   Farming-fishing   \n",
       "3046   31            Private  248178   Married-civ-spouse     Other-service   \n",
       "2162   43          State-gov   52849   Married-civ-spouse    Prof-specialty   \n",
       "\n",
       "     relationship                 race    sex  capital-gain  capital-loss  \\\n",
       "5454      Husband                White   Male             0             0   \n",
       "6111      Husband                White   Male             0             0   \n",
       "5282      Husband   Asian-Pac-Islander   Male             0             0   \n",
       "3046      Husband                Black   Male             0             0   \n",
       "2162      Husband                White   Male             0             0   \n",
       "\n",
       "      hours-per-week  native-country  \n",
       "5454              50   United-States  \n",
       "6111              55   United-States  \n",
       "5282              40   United-States  \n",
       "3046              35   United-States  \n",
       "2162              40   United-States  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data = test_data.sample(n=subsample_size, random_state=0)\n",
    "test_data_nolab = test_data.drop(columns=labels)  # unnecessary, just to demonstrate we're not cheating here\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "packed-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: education-num ...\n",
      "Predicting with TabularPredictor for label: education ...\n",
      "Predicting with TabularPredictor for label: class ...\n",
      "Predictions:  \n",
      "       education-num      education   class\n",
      "5454      10.618733   Some-college    >50K\n",
      "6111      12.840778        HS-grad    >50K\n",
      "5282       9.452595        HS-grad    >50K\n",
      "3046       9.474932        HS-grad   <=50K\n",
      "2162      12.477719        HS-grad    >50K\n",
      "...             ...            ...     ...\n",
      "6965       9.629266        HS-grad   <=50K\n",
      "4762       8.992409           11th   <=50K\n",
      "234       10.347326   Some-college   <=50K\n",
      "6291      10.311174   Some-college   <=50K\n",
      "9575      10.015663   Some-college   <=50K\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained multilabel predictor from file\n",
    "\n",
    "predictions = multi_predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "single-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TabularPredictor for label: education-num ...\n",
      "Predictive performance on given data: root_mean_squared_error = 2.185123915690999\n",
      "Evaluating TabularPredictor for label: education ...\n",
      "Predictive performance on given data: accuracy = 0.216\n",
      "Evaluating TabularPredictor for label: class ...\n",
      "Predictive performance on given data: accuracy = 0.818\n",
      "{'education-num': 2.185123915690999, 'education': 0.216, 'class': 0.818}\n",
      "Evaluated using metrics: {'education-num': root_mean_squared_error, 'education': accuracy, 'class': accuracy}\n"
     ]
    }
   ],
   "source": [
    "evaluations = multi_predictor.evaluate(test_data)\n",
    "print(evaluations)\n",
    "print(\"Evaluated using metrics:\", multi_predictor.eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-angle",
   "metadata": {},
   "source": [
    "다음과 같이 레이블 중 하나에 대해 TabularPredictor 단일 레이블을 예측할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satisfactory-clearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>1.450373</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>1.450373</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.016405</td>\n",
       "      <td>1.990871</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.540498</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>0.518251</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>0.518251</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.018446</td>\n",
       "      <td>0.314851</td>\n",
       "      <td>0.018446</td>\n",
       "      <td>0.314851</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.111939</td>\n",
       "      <td>0.756836</td>\n",
       "      <td>0.111939</td>\n",
       "      <td>0.756836</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.112039</td>\n",
       "      <td>0.866010</td>\n",
       "      <td>0.112039</td>\n",
       "      <td>0.866010</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.504494</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.504494</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.017916</td>\n",
       "      <td>0.250356</td>\n",
       "      <td>0.017916</td>\n",
       "      <td>0.250356</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.111526</td>\n",
       "      <td>0.857153</td>\n",
       "      <td>0.111526</td>\n",
       "      <td>0.857153</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.111748</td>\n",
       "      <td>0.757162</td>\n",
       "      <td>0.111748</td>\n",
       "      <td>0.757162</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>18.048697</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>18.048697</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetMXNet</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.052101</td>\n",
       "      <td>3.751938</td>\n",
       "      <td>0.052101</td>\n",
       "      <td>3.751938</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.104961</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.104961</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.104386</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.104386</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0              CatBoost       0.86       0.015572   1.450373   \n",
       "1   WeightedEnsemble_L2       0.86       0.016405   1.990871   \n",
       "2               XGBoost       0.85       0.013783   0.518251   \n",
       "3              LightGBM       0.85       0.018446   0.314851   \n",
       "4        ExtraTreesEntr       0.84       0.111939   0.756836   \n",
       "5      RandomForestGini       0.84       0.112039   0.866010   \n",
       "6         LightGBMLarge       0.83       0.017709   0.504494   \n",
       "7            LightGBMXT       0.83       0.017916   0.250356   \n",
       "8      RandomForestEntr       0.83       0.111526   0.857153   \n",
       "9        ExtraTreesGini       0.83       0.111748   0.757162   \n",
       "10      NeuralNetFastAI       0.83       0.261113  18.048697   \n",
       "11       NeuralNetMXNet       0.76       0.052101   3.751938   \n",
       "12       KNeighborsUnif       0.73       0.104961   0.003363   \n",
       "13       KNeighborsDist       0.65       0.104386   0.003238   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.015572           1.450373            1       True   \n",
       "1                 0.000834           0.540498            2       True   \n",
       "2                 0.013783           0.518251            1       True   \n",
       "3                 0.018446           0.314851            1       True   \n",
       "4                 0.111939           0.756836            1       True   \n",
       "5                 0.112039           0.866010            1       True   \n",
       "6                 0.017709           0.504494            1       True   \n",
       "7                 0.017916           0.250356            1       True   \n",
       "8                 0.111526           0.857153            1       True   \n",
       "9                 0.111748           0.757162            1       True   \n",
       "10                0.261113          18.048697            1       True   \n",
       "11                0.052101           3.751938            1       True   \n",
       "12                0.104961           0.003363            1       True   \n",
       "13                0.104386           0.003238            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           9  \n",
       "1          14  \n",
       "2          10  \n",
       "3           7  \n",
       "4           4  \n",
       "5           1  \n",
       "6          13  \n",
       "7           8  \n",
       "8           2  \n",
       "9           3  \n",
       "10         12  \n",
       "11         11  \n",
       "12          5  \n",
       "13          6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_class = multi_predictor.get_predictor('class')\n",
    "predictor_class.leaderboard(silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
